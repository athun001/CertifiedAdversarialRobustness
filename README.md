# Certified Adversarial Robustness

* Randomized Smoothing of All Shapes and Sizes
* Incremental Randomized Smoothing (IRS) https://arxiv.org/abs/2305.19521 
* Certified Adversarial Robustness via Randomized Î±-Smoothing for Regression Models
* Input-Specific Robustness Certification for Randomized Smoothing
* Higher-Order Certification for Randomized Smoothing
* Certified Robustness for Networks with Structured Outputs
* Provable defenses adversarial polytype
* DetectorGuard: Provably Securing Object Detectors against Localized Patch Hiding Attacks
* Certified defense via randomized smoothing
* Certifiably Robust Object Detection against Patch Hiding Attacks via Patch-agnostic Masking
* Detection as Regression: Certified Object Detection by Median Smoothing.
* Certified Defense to Image Transformations via Randomized Smoothing
* certified defenses against adversarial examples
* certified adversarial robustness for free
* Average Certified Radius is a Poor Metric for Randomized Smoothing
* SoK: Certified Robustness for Deep Neural Networks
* Certified Training: Small Boxes are All You Need
* Certified Robustness Under Bounded Levenshtein Distance
* On Using Certified Training towards Empirical Robustness
* Certified Adversarial Robustness via Partition-based Randomized Smoothing
* Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences
* Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization
* Projected Randomized Smoothing for Certified Adversarial Robustness
* Towards Better Certified Segmentation via Diffusion Models
* Raising the Bar for Certified Adversarial Robustness with Diffusion Models
* Certified Adversarial Robustness Within Multiple Perturbation Bounds
* Certified Robustness to Adversarial Examples with Differential Privacy
* Towards Fast Computation of Certified Robustness for ReLU Networks
* Theoretically Principled Trade-off between Robustness and Accuracy
* Efficient Neural Network Robustness Certification with General Activation Functions
* Accelerating Certified Robustness Training via Knowledge Transfer.
* Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean Function Perspective
* Certified Patch Robustness via Smoothed Vision Transformers
* Provably robust deep learning via adversarially trained smoothed classifiers
* on the effectiveness of interval bound propagation for training verifiably robust models.
* Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion
* Deep unsupervised learning using nonequilibrium thermodynamics
* Denoising diffusion probabilistic models
* Improving denoising diffusion probabilistic models
* Diffusion models for adversarial purification.
* Reducing Certified Regression to Certified Classification for General Poisoning Attacks
* Denoised smoothing: a provable defense for pretrained classifiers
* Adversarially robust generalization requires more data
* PERCEPTUAL ADVERSARIAL ROBUSTNESS: DEFENSE AGAINST UNSEEN THREAT MODELS
* Elucidating the design space of diffusion based generative models
